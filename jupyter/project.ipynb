{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본과제 CNN Tensorflow 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "Tensorflow version 1.3.0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Tensorflow version ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 레이어에서 공통으로 사용되는 Tensorboard summary 함수\n",
    "- 각 레이어 class에서 상속하기 위해 static method로 정의함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summary(object):\n",
    "  @staticmethod\n",
    "  def _summary(name, var):\n",
    "    _mean = tf.reduce_mean(var)\n",
    "    _variance = tf.reduce_mean(tf.square(var - _mean))\n",
    "    tf.summary.scalar(name+'_mean', _mean)\n",
    "    tf.summary.scalar(name+'_variance', _variance)\n",
    "    tf.summary.histogram(name, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer class\n",
    "- 2D convolution layer 구현\n",
    "- 입력된 BHWD 이미지 데이터에 대해 요청된 actication 결과를 돌려줌\n",
    "- 요청된 layer 크기에 맞춰 kernel weight와 bias를 생성하되, batch normalization이 적용될 경우는 bias를 생성하지 않음\n",
    "- 각 weight와 bias 생성시 Tensorboard summary에 각 변수에 대한 평균, 분산, 히스토그램이 추가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Summary):\n",
    "  '''\n",
    "  Construct a convolutional 2D layer and its summaries\n",
    "  args:\n",
    "    image  = input image array\n",
    "    ch_in  = input image channel size (e.g. rgb = 3)\n",
    "    ch_out = output channel size (number of kernels)\n",
    "    size   = size of kernel (patch)\n",
    "    stride = kernel (patch) stride\n",
    "    activation = activation function (cf. 'bn': for batch normalization)\n",
    "  '''\n",
    "  def __init__(self, image, ch_in, ch_out, size, stride, activation='none'):\n",
    "    self.img = image\n",
    "    self.strd = stride\n",
    "    self.act = activation.lower()\n",
    "    _W_shape = [size, size, ch_in, ch_out]\n",
    "    self.W = tf.Variable(tf.truncated_normal(_W_shape, stddev=0.1), trainable=True, name='W')\n",
    "    self._summary('W', self.W)\n",
    "    if self.act != 'bn':\n",
    "      self.B = tf.Variable(tf.constant(0.1, tf.float32, [ch_out]), trainable=True, name='B')\n",
    "      self._summary('B', self.B)\n",
    "\n",
    "  def out(self):\n",
    "    WX = tf.nn.conv2d(self.img, self.W, strides=[1, self.strd, self.strd, 1], padding='SAME')\n",
    "    if self.act == 'relu':\n",
    "      return tf.nn.relu(WX + self.B)\n",
    "    elif self.act == 'bn':\n",
    "      return WX\n",
    "    elif self.act == 'none':\n",
    "      return WX + self.B\n",
    "    else:\n",
    "      raise ValueError('ERROR: unsupported activation option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer class\n",
    "- Fully connected layer 구현\n",
    "- 기능 및 구조는 ConvLayer와 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(Summary):\n",
    "  '''\n",
    "  Construct a fully connected layer and its summaries\n",
    "  args:\n",
    "    input_ = input array\n",
    "    n_in   = input size\n",
    "    n_out  = output size\n",
    "    activation = activation function\n",
    "  '''\n",
    "  def __init__(self, input_, n_in, n_out, activation='none'):\n",
    "    self.input_ = input_\n",
    "    self.n_in = n_in\n",
    "    self.n_out = n_out\n",
    "    self.act = activation.lower()\n",
    "    self.W = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.1), trainable=True, name='W')\n",
    "    self._summary('W', self.W)\n",
    "    self.B = tf.Variable(tf.constant(0.0, tf.float32, [n_out]), trainable=True, name='B')\n",
    "    self._summary('B', self.B)\n",
    "\n",
    "  def out(self):\n",
    "    if self.act == 'relu':\n",
    "      return tf.nn.relu(tf.matmul(self.input_, self.W) + self.B)\n",
    "    elif self.act == 'none':\n",
    "      return tf.matmul(self.input_, self.W) + self.B\n",
    "    else:\n",
    "      raise ValueError('ERROR: unsupported activation option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization class\n",
    "- 입력에 대한 batch normalization을 결과를 돌려줌\n",
    "- training 시에는 입력된 각 batch의 평균과 분산을 normalization에 사용하고, test 시에는 기존 training의 전체 입력데이터에 대한 평균과 분산의 추정치(Exponential Moving Average)를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(Summary):\n",
    "  '''\n",
    "  Construct a batch normalization for input array\n",
    "  args\n",
    "    input_ = input array tensor\n",
    "    n_out  = output size\n",
    "    train  = True: train phase, False: test phase\n",
    "    activation = activation function\n",
    "  '''\n",
    "  def __init__(self, input_, n_out, train, activation='none'):\n",
    "    self.input_ = input_\n",
    "    self.act = activation.lower()\n",
    "    self.beta = tf.Variable(tf.constant(0.0, shape=[n_out]), trainable=True, name='beta')\n",
    "    self._summary('beta', self.beta)\n",
    "    self.gamma = tf.Variable(tf.constant(1.0, shape=[n_out]), trainable=True, name='gamma')\n",
    "    self._summary('gamma', self.gamma)\n",
    "    batch_mean, batch_var = tf.nn.moments(input_, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.5)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    if train:\n",
    "      with tf.control_dependencies([ema_apply_op]):\n",
    "        self.mean, self.var = tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    else:\n",
    "      self.mean, self.var = ema.average(batch_mean), ema.average(batch_var)\n",
    "\n",
    "  def out(self):\n",
    "    norm = tf.nn.batch_normalization(self.input_, self.mean, self.var, self.beta, self.gamma, 1e-3)\n",
    "    if self.act == 'relu':\n",
    "      return tf.nn.relu(norm)\n",
    "    elif self.act == 'none':\n",
    "      return norm\n",
    "    else:\n",
    "      raise ValueError('ERROR: unsupported activation option')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model 정의\n",
    "- Input image는 1000 x 1000 해상도 rgb color png파일\n",
    "- Convolution layer 4개, fully connected layer 2개로 구성\n",
    "- 첫번째 convolution layer는 batch normalization 적용\n",
    "- 각 fully connected layer는 drop out 적용 (keep probability 75%)\n",
    "- 모든 layer의 activation function은 ReLU 사용\n",
    "\n",
    "![image1.png](image1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y_, p_keep=None):\n",
    "  '''\n",
    "  Define a DNN inference model\n",
    "  args:\n",
    "    X      = input image array\n",
    "    Y_     = labels of input (solutions of Y)\n",
    "    train  = True: train phase, False: test phase\n",
    "    p_keep = keep probability of drop out, if NOT defined TEST phase model will run\n",
    "  returns:\n",
    "    Y      = predicted output array (e.g. [1, 0, 0, 0])\n",
    "    cross_entropy\n",
    "    accuracy\n",
    "    incorrects = indices of incorrect inference\n",
    "\n",
    "  X     : [1000 x 1000 x 3] HWC image volume\n",
    "  Conv1 : [100 x 100 x K1] output volume after [100 x 100 x 3] kernel with stride 10\n",
    "  Conv2 : [50 x 50 x K2] output volume after [10 x 10 x K1] kernel with stride 2\n",
    "  Conv3 : [25 x 25 x K3] output volume after [5 x 5 x K2] kernel with stride 2\n",
    "  Conv4 : [25 x 25 x K4] output volume after [3 x 3 x K3] kernel with stride 1\n",
    "  Full1 : [F1] output nodes from [25 * 25 * K4] input nodes\n",
    "  Full2 : [F2] output nodes from [F1] input nodes\n",
    "  Output: [4] ouput nodes from [F2] input nodes\n",
    "  '''\n",
    "  K1 = 10    # first conv. kernel depth\n",
    "  K2 = 20    # second conv. kernel depth\n",
    "  K3 = 40    # third conv. kernel depth\n",
    "  K4 = 20    # forth conv. kernel depth\n",
    "  F1 = 500   # first FC layer node size\n",
    "  F2 = 50    # second FC layer node size\n",
    "\n",
    "  train_phase = False if p_keep is None else True\n",
    "\n",
    "  with tf.variable_scope('Conv1'):\n",
    "    y1 = ConvLayer(X, 3, K1, 100, 10, activation='BN').out()\n",
    "    with tf.variable_scope('BN'):\n",
    "      y1 = BatchNorm(y1, K1, train_phase, activation='ReLU').out()\n",
    "  with tf.variable_scope('Conv2'):\n",
    "    y2 = ConvLayer(y1, K1, K2, 10, 2, activation='ReLU').out()\n",
    "  with tf.variable_scope('Conv3'):\n",
    "    y3 = ConvLayer(y2, K2, K3, 5, 2, activation='ReLU').out()\n",
    "  with tf.variable_scope('Conv4'):\n",
    "    y4 = ConvLayer(y3, K3, K4, 3, 1, activation='ReLU').out()\n",
    "  y4_rs = tf.reshape(y4, shape=[-1, 25*25*K4])\n",
    "\n",
    "  with tf.variable_scope('Full1'):\n",
    "    y5 = FCLayer(y4_rs, 25*25*K4, F1, activation='ReLU').out()\n",
    "    if train_phase: y5 = tf.nn.dropout(y5, p_keep)\n",
    "  with tf.variable_scope('Full2'):\n",
    "    y6 = FCLayer(y5, F1, F2, activation='ReLU').out()\n",
    "    if train_phase: y6 = tf.nn.dropout(y6, p_keep)\n",
    "  with tf.variable_scope('Output'):\n",
    "    Ylogits = FCLayer(y6, F2, 4).out()\n",
    "  Y = tf.nn.softmax(Ylogits, name='Y')\n",
    "\n",
    "  with tf.variable_scope('cross_entropy'):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "  with tf.variable_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    incorrects = tf.squeeze(tf.where(tf.logical_not(correct_prediction)), [1])\n",
    "\n",
    "  return Y, cross_entropy, accuracy, incorrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow runtime sessions\n",
    "### 1. png image를 array data로 변환\n",
    "- input image는 png 파일 포멧으로 [모터속도Hz]-[토크%]-[수집일련번호]-[상태번호] 의 이름을 가짐 (예: 25Hz-50%-251-0.png)\n",
    "- [상태번호]는 0: 정상, 1: stator fault, 2: rotor fault, 3: bearing fault로 정의\n",
    "- 지정된 directory에서 전체 png 파일 목록을 가져온 후, 각 파일의 path를 <b><i>png</i></b> array에 저장하고, 해당 파일의 이미지 raw 데이터를 array로 변환하여 <b><i>X</i></b> array에 저장, 파일명으로 부터 상태번호를 추출하여 <b><i>Y_</i></b> array에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(file_path, batch_size=1, one_hot=True, shuffle=True):\n",
    "  '''\n",
    "  Generate input data batches from png images\n",
    "  args\n",
    "    file_path  = input image(png) file path\n",
    "    batch_size = batch size for each training step\n",
    "    one_hot    = True: output labels (Y_) as one_hot arrays\n",
    "    shuffle    = True: shuffle data queue sequence\n",
    "  return\n",
    "    data = {'X':[X1, ..., Xn], 'Y_':[Y_1, ..., Y_n], 'png':[png_path1, ..., png_pathn]}\n",
    "  '''\n",
    "  data = {}\n",
    "  files = [os.path.join(file_path, s) for s in os.listdir(file_path)]\n",
    "  queue = tf.train.string_input_producer(files, shuffle=shuffle)\n",
    "  reader = tf.WholeFileReader()\n",
    "  file_path, contents = reader.read(queue)\n",
    "  img = tf.image.decode_png(contents, channels=3)\n",
    "  with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    raw = [sess.run([file_path, img]) for _ in files]\n",
    "    data['png'] = [f_i[0].decode() for f_i in raw]\n",
    "    data['X'] = [f_i[1] for f_i in raw]\n",
    "    data['Y_'] = [int(p.strip('.png').split('-')[3]) for p in data['png']]\n",
    "    if one_hot: data['Y_'] = sess.run(tf.one_hot(data['Y_'],4))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input image 예시\n",
    "- 상단 좌측부터 우측으로 정상, stator fault, rotor fault, bearing fault 순\n",
    "    - Red: 전류 2채널 (phase A, B) raw data에 대한 correlation matrix image\n",
    "    - Green: 전압 2채널 (phase A, B) raw data에 대한 correlation matrix image\n",
    "    - Blue: 진동 2채널 (axis y, z) raw data에 대한 correlation matrix image\n",
    "- [참고] 각 이미지는 사람이 확인하기 쉽도록 실제 이미지보다 밝기가 증가되어 있음\n",
    "\n",
    "![image2.png](image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. training phase\n",
    "- adam optimizer 사용\n",
    "- learning rate는 0.001 에서 시작하여 5단계에 걸친 exponential decay 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(MAX_STEP, BATCH_SIZE, INPUT_PATH, MODEL_PATH, LOG_DIR):\n",
    "    startTime = time.time()\n",
    "    # input generation\n",
    "    with tf.Graph().as_default() as input_g:\n",
    "      data = gen_data(INPUT_PATH, BATCH_SIZE)\n",
    "      n_data = len(data['png'])\n",
    "      print('[%6.2f] successfully generated train data: %d samples'%(time.time()-startTime, n_data))\n",
    "\n",
    "    # training phase\n",
    "    with tf.Graph().as_default() as train_g:\n",
    "      # input X: 1000 x 1000 rgb color image\n",
    "      X = tf.placeholder(tf.float32, [None, 1000, 1000, 3], name='X')\n",
    "      # target values Y_: 0=normal, 1=stator fault, 2=rotor fault, 3=bearing fault\n",
    "      Y_ = tf.placeholder(tf.float32, [None, 4], name='Y_')\n",
    "      with tf.variable_scope('Config'):\n",
    "        # dropout keep probability\n",
    "        p_keep = tf.placeholder(tf.float32, name='p_keep')\n",
    "        # learning rate\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        lr = tf.train.exponential_decay(0.001, global_step, int(MAX_STEP/5), 0.5, staircase=True, name='lr')\n",
    "\n",
    "      # load inference model\n",
    "      Y, cross_entropy, accuracy, _ = model(X, Y_, p_keep)\n",
    "      train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy, global_step=global_step)\n",
    "\n",
    "      with tf.variable_scope('Metrics'):\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "        tf.summary.scalar('learning_rate', lr)\n",
    "                                                                                                                        \n",
    "      # set tensorboard summary and saver\n",
    "      merged = tf.summary.merge_all()\n",
    "      saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "      # training session\n",
    "      print('----- training start -----')\n",
    "      with tf.Session() as sess:\n",
    "        sum_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "        tf.global_variables_initializer().run()\n",
    "        step = 1\n",
    "        while step <= MAX_STEP:\n",
    "          for batch in range(int(n_data/BATCH_SIZE)+1):\n",
    "            s = batch*BATCH_SIZE\n",
    "            e = (batch+1)*BATCH_SIZE if (batch+1)*BATCH_SIZE < n_data else n_data\n",
    "            if e <= s: break\n",
    "            _, summary, acc, ent = sess.run([train_op, merged, accuracy, cross_entropy],\n",
    "                                            {X:data['X'][s:e], Y_:data['Y_'][s:e], p_keep:0.75})\n",
    "            sum_writer.add_summary(summary, step)\n",
    "            print('[%6.2f] step:%3d, size:%3d, lr:%f, accuracy:%f, cross entropy:%f'\n",
    "                  %(time.time()-startTime, step, e-s, lr.eval(), acc, ent))\n",
    "            if (MAX_STEP-step)<10 or step%100==0:\n",
    "              saver.save(sess, MODEL_PATH, global_step=step)\n",
    "            step += 1\n",
    "            if step > MAX_STEP: break\n",
    "      print('-----  training end  -----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행 예\n",
    "- <i>INPUT</i>: training에 사용할 png image directory 경로 지정\n",
    "- <i>SAVE</i>: training이 완료된 network parameter 저장경로 지정\n",
    "- <i>LOG</i>: Tensorboard log 저장경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13.23] successfully generated train data: 1184 samples\n",
      "----- training start -----\n",
      "[282.15] step:  1, size:120, lr:0.001000, accuracy:0.216667, cross entropy:27.592012\n",
      "[284.63] step:  2, size:120, lr:0.001000, accuracy:0.300000, cross entropy:6.706369\n",
      "[287.11] step:  3, size:120, lr:0.001000, accuracy:0.241667, cross entropy:6.977856\n",
      "[289.58] step:  4, size:120, lr:0.001000, accuracy:0.300000, cross entropy:3.377185\n",
      "[292.06] step:  5, size:120, lr:0.001000, accuracy:0.300000, cross entropy:2.045619\n",
      "[294.53] step:  6, size:120, lr:0.000500, accuracy:0.325000, cross entropy:1.575463\n",
      "[297.01] step:  7, size:120, lr:0.000500, accuracy:0.275000, cross entropy:1.592177\n",
      "[299.50] step:  8, size:120, lr:0.000500, accuracy:0.275000, cross entropy:1.564621\n",
      "[301.97] step:  9, size:120, lr:0.000500, accuracy:0.291667, cross entropy:1.513112\n",
      "[565.96] step: 10, size:104, lr:0.000500, accuracy:0.298077, cross entropy:1.492568\n",
      "[568.48] step: 11, size:120, lr:0.000500, accuracy:0.375000, cross entropy:1.382447\n",
      "[570.97] step: 12, size:120, lr:0.000250, accuracy:0.333333, cross entropy:1.345186\n",
      "[573.46] step: 13, size:120, lr:0.000250, accuracy:0.383333, cross entropy:1.369876\n",
      "[575.95] step: 14, size:120, lr:0.000250, accuracy:0.383333, cross entropy:1.362009\n",
      "[578.84] step: 15, size:120, lr:0.000250, accuracy:0.375000, cross entropy:1.393385\n",
      "[581.38] step: 16, size:120, lr:0.000250, accuracy:0.341667, cross entropy:1.378198\n",
      "[583.85] step: 17, size:120, lr:0.000250, accuracy:0.341667, cross entropy:1.367950\n",
      "[586.32] step: 18, size:120, lr:0.000125, accuracy:0.341667, cross entropy:1.335805\n",
      "[588.80] step: 19, size:120, lr:0.000125, accuracy:0.358333, cross entropy:1.334626\n",
      "[590.96] step: 20, size:104, lr:0.000125, accuracy:0.278846, cross entropy:1.394738\n",
      "[593.45] step: 21, size:120, lr:0.000125, accuracy:0.350000, cross entropy:1.323875\n",
      "[596.02] step: 22, size:120, lr:0.000125, accuracy:0.366667, cross entropy:1.289862\n",
      "[598.57] step: 23, size:120, lr:0.000125, accuracy:0.416667, cross entropy:1.304380\n",
      "[601.13] step: 24, size:120, lr:0.000063, accuracy:0.341667, cross entropy:1.328330\n",
      "[603.69] step: 25, size:120, lr:0.000063, accuracy:0.400000, cross entropy:1.319643\n",
      "[606.24] step: 26, size:120, lr:0.000063, accuracy:0.433333, cross entropy:1.305296\n",
      "[608.80] step: 27, size:120, lr:0.000063, accuracy:0.316667, cross entropy:1.351926\n",
      "[611.36] step: 28, size:120, lr:0.000063, accuracy:0.275000, cross entropy:1.369204\n",
      "[613.93] step: 29, size:120, lr:0.000063, accuracy:0.383333, cross entropy:1.344195\n",
      "[616.16] step: 30, size:104, lr:0.000031, accuracy:0.326923, cross entropy:1.344097\n",
      "-----  training end  -----\n"
     ]
    }
   ],
   "source": [
    "INPUT='/mnt/data/camus/images/20170919/'\n",
    "SAVE='/mnt/data/camus/project/tmp/train/model/ckpt'\n",
    "LOG='/mnt/data/camus/project/tmp/train/log/'\n",
    "\n",
    "# do train with batch size 120 and maximum step 30\n",
    "do_train(30, 120, INPUT, SAVE, LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 학습 횟수(max step) <b>3000</b> 정도에서 전체 parameter의 수렴이 완료되는 것으로 확인\n",
    "\n",
    "![image3.png](image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. test phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(BATCH_SIZE, INPUT_PATH, MODEL_PATH, LOG_DIR):\n",
    "  startTime = time.time()\n",
    "  # input generation\n",
    "  with tf.Graph().as_default() as input_g:\n",
    "    data = gen_data(INPUT_PATH, shuffle=False)\n",
    "    n_data = len(data['png'])\n",
    "    print('[%6.2f] successfully generated test data: %d samples'%(time.time()-startTime, n_data))\n",
    "\n",
    "  # test phase\n",
    "  with tf.Graph().as_default() as test_g:\n",
    "    # input X: 1000 x 1000 rgb color image\n",
    "    X = tf.placeholder(tf.float32, [None, 1000, 1000, 3], name='X')\n",
    "    # target values Y_: 0=normal, 1=stator fault, 2=rotor fault, 3=bearing fault\n",
    "    Y_ = tf.placeholder(tf.float32, [None, 4], name='Y_')\n",
    "\n",
    "    # load inference model\n",
    "    Y, cross_entropy, accuracy, incorrects = model(X, Y_)\n",
    "\n",
    "    with tf.variable_scope('Metrics'):\n",
    "      tf.summary.scalar('accuracy', accuracy)\n",
    "      tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "    # set tensorboard summary and saver\n",
    "    merged = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # test session\n",
    "    print('----- test start -----')\n",
    "    with tf.Session() as sess:\n",
    "      sum_writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "      tf.global_variables_initializer().run()\n",
    "      saver.restore(sess, MODEL_PATH)\n",
    "      avg_accuracy = 0\n",
    "      for step in range(int(n_data/BATCH_SIZE)+1):\n",
    "        s = step*BATCH_SIZE\n",
    "        e = (step+1)*BATCH_SIZE if (step+1)*BATCH_SIZE < n_data else n_data\n",
    "        if e <= s: break\n",
    "        summary, acc, ent, incor, y_, y = sess.run([merged, accuracy, cross_entropy, incorrects, Y_, Y],\n",
    "                                                    {X:data['X'][s:e], Y_:data['Y_'][s:e]})\n",
    "        sum_writer.add_summary(summary, step+1)\n",
    "        avg_accuracy += acc * (e-s)\n",
    "        print('[%6.2f] step:%d, size:%d, accuracy:%f, cross entropy:%f'\n",
    "                %(time.time()-startTime, step+1, e-s, acc, ent))\n",
    "        if len(incor) > 0: print('   incorrects list:')\n",
    "        for i in incor:\n",
    "          print('   [%3d] Answer:Infer = %d:%d  at %s'\n",
    "                  %(s+i, tf.argmax(y_[i],0).eval(),tf.argmax(y[i],0).eval(),data['png'][s+i]))\n",
    "      print('-----  test end  -----')\n",
    "      print('[%6.2f] total average accuracy: %f'%(time.time()-startTime, avg_accuracy/n_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실행 예\n",
    "- <i>INPUT</i>: test에 사용할 png image directory 경로 지정\n",
    "- <i>MODEL</i>: test에 사용할 학습된 network parameter 경로 지정<br>\n",
    "총 1184개 image에 대해 batch size 120, max steps 3000으로 학습된 모델 사용\n",
    "- <i>LOG</i>: Tensorboard log 저장경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.10] successfully generated test data: 200 samples\n",
      "----- test start -----\n",
      "INFO:tensorflow:Restoring parameters from /mnt/data/camus/project/tmp/test/model/ckpt\n",
      "[  5.18] step:1, size:100, accuracy:1.000000, cross entropy:0.000251\n",
      "[  6.01] step:2, size:100, accuracy:1.000000, cross entropy:0.003246\n",
      "-----  test end  -----\n",
      "[  6.01] total average accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "INPUT='/mnt/data/camus/images/20170830/'\n",
    "MODEL='/mnt/data/camus/project/tmp/test/model/ckpt'\n",
    "LOG='/mnt/data/camus/project/tmp/test/log/'\n",
    "\n",
    "# do test with batch size 100 and pre-trained model parameters\n",
    "do_test(100, INPUT, MODEL, LOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test 결과 200개 데이터에 대해 예측 정확도 <b>100%</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
